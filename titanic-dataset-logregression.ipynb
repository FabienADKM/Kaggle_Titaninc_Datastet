{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-14T15:45:20.769148Z","iopub.execute_input":"2021-11-14T15:45:20.769446Z","iopub.status.idle":"2021-11-14T15:45:20.77799Z","shell.execute_reply.started":"2021-11-14T15:45:20.769412Z","shell.execute_reply":"2021-11-14T15:45:20.777313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set =  '/kaggle/input/titanic/train.csv'\n\ndf = pd.read_csv(train_set)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.779529Z","iopub.execute_input":"2021-11-14T15:45:20.779752Z","iopub.status.idle":"2021-11-14T15:45:20.805956Z","shell.execute_reply.started":"2021-11-14T15:45:20.779725Z","shell.execute_reply":"2021-11-14T15:45:20.805071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.807372Z","iopub.execute_input":"2021-11-14T15:45:20.807629Z","iopub.status.idle":"2021-11-14T15:45:20.838279Z","shell.execute_reply.started":"2021-11-14T15:45:20.8076Z","shell.execute_reply":"2021-11-14T15:45:20.837606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.839208Z","iopub.execute_input":"2021-11-14T15:45:20.839415Z","iopub.status.idle":"2021-11-14T15:45:20.852286Z","shell.execute_reply.started":"2021-11-14T15:45:20.839392Z","shell.execute_reply":"2021-11-14T15:45:20.851461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first thing one can see with a first look at the dataset is the presence of missing values in the following columns : *Cabin*, *Embarked* and *Age*. We then choose to drop the 'Cabin' columns due to its too great number of missing values and to drop the passenger who haven't their age repertoried in the dataset.","metadata":{}},{"cell_type":"code","source":"df_preprocessed = df.drop(columns = ['Cabin','Name','Ticket'])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.853881Z","iopub.execute_input":"2021-11-14T15:45:20.854077Z","iopub.status.idle":"2021-11-14T15:45:20.858599Z","shell.execute_reply.started":"2021-11-14T15:45:20.854053Z","shell.execute_reply":"2021-11-14T15:45:20.857813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preprocessed = df_preprocessed.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.859758Z","iopub.execute_input":"2021-11-14T15:45:20.860313Z","iopub.status.idle":"2021-11-14T15:45:20.87244Z","shell.execute_reply.started":"2021-11-14T15:45:20.860253Z","shell.execute_reply":"2021-11-14T15:45:20.871577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preprocessed['Fare'].plot(kind='box', vert=False, figsize=(14,6))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:20.873972Z","iopub.execute_input":"2021-11-14T15:45:20.874468Z","iopub.status.idle":"2021-11-14T15:45:21.058184Z","shell.execute_reply.started":"2021-11-14T15:45:20.874427Z","shell.execute_reply":"2021-11-14T15:45:21.057285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = np.linspace(df_preprocessed.Age.min(), df_preprocessed.Age.max(), 10)\ng = sns.FacetGrid(df, col=\"Sex\", hue=\"Survived\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.059252Z","iopub.execute_input":"2021-11-14T15:45:21.059509Z","iopub.status.idle":"2021-11-14T15:45:21.490794Z","shell.execute_reply.started":"2021-11-14T15:45:21.059482Z","shell.execute_reply":"2021-11-14T15:45:21.490072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preprocessed.groupby(['Sex'])['Survived'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.4923Z","iopub.execute_input":"2021-11-14T15:45:21.492687Z","iopub.status.idle":"2021-11-14T15:45:21.502184Z","shell.execute_reply.started":"2021-11-14T15:45:21.492652Z","shell.execute_reply":"2021-11-14T15:45:21.501198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here one can see that on the preprocessed data that the women seems to survive better than men and that the younger men are also more prone to survive. Now let's convert male to 0 and female to 1:","metadata":{}},{"cell_type":"code","source":"df_preprocessed['Sex'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf_preprocessed.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.504357Z","iopub.execute_input":"2021-11-14T15:45:21.504563Z","iopub.status.idle":"2021-11-14T15:45:21.519697Z","shell.execute_reply.started":"2021-11-14T15:45:21.50454Z","shell.execute_reply":"2021-11-14T15:45:21.519096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also encode in one hot the values the embarked gate characteristics","metadata":{}},{"cell_type":"code","source":"df_preprocessed = pd.concat([df_preprocessed,pd.get_dummies(df_preprocessed['Embarked'])], axis=1)\ndf_preprocessed.drop(['Embarked'], axis = 1,inplace=True)\ndf_preprocessed.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.52102Z","iopub.execute_input":"2021-11-14T15:45:21.52127Z","iopub.status.idle":"2021-11-14T15:45:21.54333Z","shell.execute_reply.started":"2021-11-14T15:45:21.521225Z","shell.execute_reply":"2021-11-14T15:45:21.542584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = df_preprocessed.corr()\n\ncorr","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.544449Z","iopub.execute_input":"2021-11-14T15:45:21.544647Z","iopub.status.idle":"2021-11-14T15:45:21.562775Z","shell.execute_reply.started":"2021-11-14T15:45:21.544624Z","shell.execute_reply":"2021-11-14T15:45:21.562181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nplt.matshow(corr, cmap='RdBu', fignum=fig.number)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical');\nplt.yticks(range(len(corr.columns)), corr.columns);","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.563674Z","iopub.execute_input":"2021-11-14T15:45:21.564338Z","iopub.status.idle":"2021-11-14T15:45:21.943978Z","shell.execute_reply.started":"2021-11-14T15:45:21.564303Z","shell.execute_reply":"2021-11-14T15:45:21.943196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_preprocessed[['PassengerId','Pclass','Sex','Age','Parch','Fare','C','Q','S']]\nnames = ['PassengerId','Pclass','Sex','Age','Parch','Fare','C','Q','S'] #Â variable names\ny = df_preprocessed['Survived']","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.945648Z","iopub.execute_input":"2021-11-14T15:45:21.945926Z","iopub.status.idle":"2021-11-14T15:45:21.95233Z","shell.execute_reply.started":"2021-11-14T15:45:21.945888Z","shell.execute_reply":"2021-11-14T15:45:21.95152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom time import time\nfrom sklearn.svm import l1_min_c\n\nX = preprocessing.StandardScaler().fit(X).transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.953798Z","iopub.execute_input":"2021-11-14T15:45:21.954071Z","iopub.status.idle":"2021-11-14T15:45:21.966567Z","shell.execute_reply.started":"2021-11-14T15:45:21.954036Z","shell.execute_reply":"2021-11-14T15:45:21.965853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cs = l1_min_c(X, y, loss='log') * np.logspace(0, 4, 30)\n\nprint(\"Computing regularization path ...\")\nstart = time()\nclf = LogisticRegression(penalty='l1', solver='saga',\n                                      tol=1e-6, max_iter=int(1e6),\n                                      warm_start=True)\ncoefs_ = []\nbeta_l1norm = []\nfor c in cs:\n    clf.set_params(C=c)\n    clf.fit(X, y)\n    beta_l1norm.append( np.sum(np.abs(clf.coef_.ravel()))) \n    coefs_.append(clf.coef_.ravel().copy())\nprint(\"This took %0.3fs\" % (time() - start))\n\nbetas = np.array(coefs_)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:21.967631Z","iopub.execute_input":"2021-11-14T15:45:21.968128Z","iopub.status.idle":"2021-11-14T15:45:22.138402Z","shell.execute_reply.started":"2021-11-14T15:45:21.968095Z","shell.execute_reply":"2021-11-14T15:45:22.137512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display lasso path Vs l1 norm of the coeff vector\nplt.figure(figsize=(12,6))\n#plt.plot(np.log10(cs), coefs_, marker='o')\nplt.plot(beta_l1norm, betas, marker='o')\nymin, ymax = plt.ylim()\nplt.xlabel('l1 norm of beta')\nplt.ylabel('Coefficients')\nplt.title('Logistic Regression Path')\nplt.axis('tight')\nplt.legend(names, fontsize=14)\nplt.grid('On')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:22.139541Z","iopub.execute_input":"2021-11-14T15:45:22.139748Z","iopub.status.idle":"2021-11-14T15:45:22.465466Z","shell.execute_reply.started":"2021-11-14T15:45:22.139723Z","shell.execute_reply":"2021-11-14T15:45:22.464672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n\nprint(\"Computing K-fold CV ...\")\n# K fold cross validation  (K=5)\nstart = time()\ncs = l1_min_c(X_train, y_train, loss='log') * np.logspace(0, 2, 50) # the vector for the alpha (lasso penalty parameter) values\nmodel = LogisticRegressionCV(Cs=cs, cv=5, penalty='l1', solver='saga', tol=1e-6).fit(X_train,y_train)\nprint(\"This took %0.3fs\" % (time() - start))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:22.46658Z","iopub.execute_input":"2021-11-14T15:45:22.466879Z","iopub.status.idle":"2021-11-14T15:45:22.910964Z","shell.execute_reply.started":"2021-11-14T15:45:22.466848Z","shell.execute_reply":"2021-11-14T15:45:22.910111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now model is tuned with the penalty parameter estimated by CV\nlambda_cv = model.C_[0]\n# The coef estimated with CV\nbeta_l1norm = np.sum(np.abs(model.coef_))\n\nprint('CV estimates:')\nprint('- lambda = {:.3f}, which yields ||beta||_1 = {:.3f}\\n'.format(lambda_cv,beta_l1norm) )\nprint('CV weights for standardized variables:')\nbetas_cv = pd.DataFrame.from_records(model.coef_, columns=names, index=['Weights'])\nbetas_cv['intercept'] = clf.intercept_\nbetas_cv.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:22.912182Z","iopub.execute_input":"2021-11-14T15:45:22.913425Z","iopub.status.idle":"2021-11-14T15:45:22.93438Z","shell.execute_reply.started":"2021-11-14T15:45:22.91338Z","shell.execute_reply":"2021-11-14T15:45:22.933552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = model.predict(X_test)\nprint(\"\\nResults for the Test data set: %0.3f\" % accuracy_score(y_test, y_pred) )","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:48:18.935053Z","iopub.execute_input":"2021-11-14T15:48:18.935541Z","iopub.status.idle":"2021-11-14T15:48:18.942534Z","shell.execute_reply.started":"2021-11-14T15:48:18.935495Z","shell.execute_reply":"2021-11-14T15:48:18.941419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:50:59.078735Z","iopub.execute_input":"2021-11-14T15:50:59.079284Z","iopub.status.idle":"2021-11-14T15:50:59.084463Z","shell.execute_reply.started":"2021-11-14T15:50:59.07923Z","shell.execute_reply":"2021-11-14T15:50:59.08386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix analysis\n\ncl = [0,1]\ny_pred = clf.predict(X_test)\ncm =confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(cm, index = [i for i in cl],\n                  columns = [i for i in cl])\nplt.figure(figsize = (5,4))\nsns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\nplt.xlabel('Predicted classes')\nplt.ylabel('Actual classes')\nplt.title('Confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:51:02.932384Z","iopub.execute_input":"2021-11-14T15:51:02.93282Z","iopub.status.idle":"2021-11-14T15:51:03.1602Z","shell.execute_reply.started":"2021-11-14T15:51:02.93279Z","shell.execute_reply":"2021-11-14T15:51:03.159322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# further indices\np = precision_score(y_test, y_pred, average=None)\nr = recall_score(y_test, y_pred, average=None)\nfs = f1_score(y_test, y_pred, average=None)\ndf_metrics = pd.DataFrame({'Precision':p,\n                            'Recall':r,\n                            'F1 Score': fs},\n                            index = cl)\ndf_metrics","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:51:21.25903Z","iopub.execute_input":"2021-11-14T15:51:21.259444Z","iopub.status.idle":"2021-11-14T15:51:21.274464Z","shell.execute_reply.started":"2021-11-14T15:51:21.259415Z","shell.execute_reply":"2021-11-14T15:51:21.273356Z"},"trusted":true},"execution_count":null,"outputs":[]}]}